"""
ç”µå½±æ¨èç³»ç»Ÿ - å¤šç®—æ³•é›†æˆç‰ˆæœ¬
ä½¿ç”¨äººå£ç»Ÿè®¡å­¦è¿‡æ»¤ã€åŸºäºå†…å®¹è¿‡æ»¤å’Œæ·±åº¦å­¦ä¹ æ¨è
"""

# åŸºç¡€åº“å¯¼å…¥
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.metrics.pairwise import linear_kernel, cosine_similarity
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from ast import literal_eval

# æ·±åº¦å­¦ä¹ åº“å¯¼å…¥
import tensorflow as tf
from tensorflow import keras
import warnings
warnings.filterwarnings('ignore')

# ======================== æ•°æ®åŠ è½½ ========================
path = "C:/Users/18304/OneDrive - whu.edu.cn/æ¡Œé¢/movies recommend/archive"
credits_df = pd.read_csv(path + "/tmdb_5000_credits.csv")
movies_df = pd.read_csv(path + "/tmdb_5000_movies.csv")
credits_df.columns = ['id','tittle','cast','crew']
movies_df = movies_df.merge(credits_df, on="id")

# ======================== äººå£ç»Ÿè®¡å­¦æ¨è ========================
# IMDBåŠ æƒè¯„åˆ†ï¼šWR = (v/(v+m)) * R + (m/(v+m)) * C
C = movies_df["vote_average"].mean()  # æ‰€æœ‰ç”µå½±çš„å¹³å‡è¯„åˆ†
m = movies_df["vote_count"].quantile(0.9)  # 90%åˆ†ä½æ•°çš„æŠ•ç¥¨æ•°é˜ˆå€¼
new_movies_df = movies_df.copy().loc[movies_df["vote_count"] >= m]


def weighted_rating(x, C=C, m=m):
    """è®¡ç®—IMDBåŠ æƒè¯„åˆ†"""
    v = x["vote_count"]  # æŠ•ç¥¨æ•°
    R = x["vote_average"]  # å¹³å‡è¯„åˆ†
    return (v/(v + m) * R) + (m/(v + m) * C)

new_movies_df["score"] = new_movies_df.apply(weighted_rating, axis=1)
new_movies_df = new_movies_df.sort_values('score', ascending=False)
top_movies = new_movies_df[["title", "vote_count", "vote_average", "score"]].head(10)


# æµè¡Œåº¦å¯è§†åŒ–å‡½æ•°
def plot():
    """ç»˜åˆ¶æœ€å—æ¬¢è¿çš„10éƒ¨ç”µå½±"""
    popularity = movies_df.sort_values("popularity", ascending=False)
    plt.figure(figsize=(12, 6))
    plt.barh(popularity["title"].head(10), popularity["popularity"].head(10), align="center", color="skyblue")
    plt.gca().invert_yaxis()
    plt.title("Top 10 movies")
    plt.xlabel("Popularity")
    plt.show()

plot() 

# ======================== åŸºäºå†…å®¹çš„æ¨è ========================
movies_df["overview"] = movies_df["overview"].fillna("")
tfidf = TfidfVectorizer(stop_words="english")
tfidf_matrix = tfidf.fit_transform(movies_df["overview"])

# è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)
indices = pd.Series(movies_df.index, index=movies_df["title"]).drop_duplicates()

def get_recommendations(title, cosine_sim=cosine_sim):
    """
    åŸºäºä½™å¼¦ç›¸ä¼¼åº¦çš„ç”µå½±æ¨èå‡½æ•°
    1. è·å–ç›®æ ‡ç”µå½±çš„ç´¢å¼•
    2. è®¡ç®—ä¸æ‰€æœ‰ç”µå½±çš„ç›¸ä¼¼åº¦åˆ†æ•°
    3. æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œå–å‰10éƒ¨ç”µå½±
    4. è¿”å›æ¨èç”µå½±æ ‡é¢˜åˆ—è¡¨
    """
    idx = indices[title]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]  # æ’é™¤è‡ªèº«ï¼Œå–å‰10ä¸ª
    
    movies_indices = [ind[0] for ind in sim_scores]
    movies = movies_df["title"].iloc[movies_indices]
    return movies




# åŸºäºå†…å®¹æ¨èç»“æœå±•ç¤º
print("åŸºäºå†…å®¹çš„æ¨èç»“æœ:")
print("\nã€ŠThe Dark Knight Risesã€‹ç›¸ä¼¼ç”µå½±:")
print(get_recommendations("The Dark Knight Rises"))
print("\nã€ŠThe Avengersã€‹ç›¸ä¼¼ç”µå½±:")
print(get_recommendations("The Avengers"))

# ======================== åŸºäºå…ƒæ•°æ®çš„å†…å®¹æ¨è ========================
features = ["cast", "crew", "keywords", "genres"]
for feature in features:
    movies_df[feature] = movies_df[feature].apply(literal_eval)

def get_director(x):
    """ä»crewæ•°æ®ä¸­æå–å¯¼æ¼”ä¿¡æ¯"""
    for i in x:
        if i["job"] == "Director":
            return i["name"]
    return np.nan

def get_list(x):
    """æå–å‰3ä¸ªåç§°ï¼ˆæ¼”å‘˜ã€å…³é”®è¯ç­‰ï¼‰"""
    if isinstance(x, list):
        names = [i["name"] for i in x]
        if len(names) > 3:
            names = names[:3]
        return names
    return []

# æå–ç‰¹å¾
movies_df["director"] = movies_df["crew"].apply(get_director)
features = ["cast", "keywords", "genres"]
for feature in features:
    movies_df[feature] = movies_df[feature].apply(get_list)

def clean_data(x):
    """æ¸…ç†æ–‡æœ¬æ•°æ®ï¼šè½¬å°å†™ã€å»ç©ºæ ¼"""
    if isinstance(x, list):
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        if isinstance(x, str):
            return str.lower(x.replace(" ", ""))
        else:
            return ""


# åº”ç”¨æ•°æ®æ¸…ç†
features = ['cast', 'keywords', 'director', 'genres']
for feature in features:
    movies_df[feature] = movies_df[feature].apply(clean_data)

def create_soup(x):
    """å°†æ‰€æœ‰ç‰¹å¾ç»„åˆæˆä¸€ä¸ªå­—ç¬¦ä¸²"""
    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])

movies_df["soup"] = movies_df.apply(create_soup, axis=1)

# åŸºäºå…ƒæ•°æ®çš„å‘é‡åŒ–å’Œç›¸ä¼¼åº¦è®¡ç®—
count_vectorizer = CountVectorizer(stop_words="english")
count_matrix = count_vectorizer.fit_transform(movies_df["soup"])
cosine_sim2 = cosine_similarity(count_matrix, count_matrix)

movies_df = movies_df.reset_index()
indices = pd.Series(movies_df.index, index=movies_df['title'])

# å…ƒæ•°æ®æ¨èç»“æœå±•ç¤º
print("\n################ åŸºäºå…ƒæ•°æ®çš„å†…å®¹æ¨è #############")
print("ã€ŠThe Dark Knight Risesã€‹æ¨è:")
print(get_recommendations("The Dark Knight Rises", cosine_sim2))
print("\nã€ŠThe Avengersã€‹æ¨è:")
print(get_recommendations("The Avengers", cosine_sim2))


# ======================== æ·±åº¦å­¦ä¹ æ¨èç³»ç»Ÿ ========================

class DeepLearningRecommendationSystem:
    """åŸºäºç¥ç»ç½‘ç»œçš„ç”µå½±æ¨èç³»ç»Ÿ - ç¥ç»ååŒè¿‡æ»¤(NCF)"""
    
    def __init__(self, embedding_size=50, hidden_units=[128, 64, 32]):
        self.embedding_size = embedding_size
        self.hidden_units = hidden_units
        self.model = None
        self.user_encoder = LabelEncoder()
        self.movie_encoder = LabelEncoder()
        
    def prepare_data(self, movies_df):
        """å‡†å¤‡è®­ç»ƒæ•°æ® - åŸºäºç”µå½±è¯„åˆ†å’Œæµè¡Œåº¦åˆ›å»ºè™šæ‹Ÿç”¨æˆ·-ç”µå½±äº¤äº’æ•°æ®"""
        print("æ­£åœ¨å‡†å¤‡æ·±åº¦å­¦ä¹ è®­ç»ƒæ•°æ®...")
        np.random.seed(42)
        user_movie_interactions = []
        
        for idx, movie in movies_df.iterrows():
            # åŸºäºç”µå½±è¯„åˆ†å’ŒæŠ•ç¥¨æ•°ç”Ÿæˆè™šæ‹Ÿç”¨æˆ·æ•°
            popularity_factor = min(movie['vote_count'] / 100, 50)
            num_users = max(int(popularity_factor), 5)
            
            for user_id in range(num_users):
                # åŸºäºçœŸå®è¯„åˆ†æ·»åŠ å™ªå£°ç”Ÿæˆè™šæ‹Ÿè¯„åˆ†
                base_rating = movie['vote_average']
                noise = np.random.normal(0, 0.5)
                rating = max(1, min(10, base_rating + noise))
                
                user_movie_interactions.append({
                    'user_id': f'user_{idx}_{user_id}',
                    'movie_id': movie['id'],
                    'rating': rating,
                    'movie_title': movie['title']
                })
        
        interactions_df = pd.DataFrame(user_movie_interactions)
        interactions_df['user_encoded'] = self.user_encoder.fit_transform(interactions_df['user_id'])
        interactions_df['movie_encoded'] = self.movie_encoder.fit_transform(interactions_df['movie_id'])
        
        print(f"ç”Ÿæˆäº† {len(interactions_df)} ä¸ªç”¨æˆ·-ç”µå½±äº¤äº’è®°å½•")
        print(f"ç”¨æˆ·æ•°: {interactions_df['user_encoded'].nunique()}")
        print(f"ç”µå½±æ•°: {interactions_df['movie_encoded'].nunique()}")
        return interactions_df
    
    def build_model(self, num_users, num_movies):
        """æ„å»ºç¥ç»ååŒè¿‡æ»¤æ¨¡å‹"""
        print("æ„å»ºç¥ç»ååŒè¿‡æ»¤æ¨¡å‹...")
        
        # ç”¨æˆ·åµŒå…¥å±‚
        user_input = keras.layers.Input(shape=(), name='user_id')
        user_embedding = keras.layers.Embedding(num_users, self.embedding_size, name='user_embedding')(user_input)
        user_vec = keras.layers.Flatten(name='user_flatten')(user_embedding)
        
        # ç”µå½±åµŒå…¥å±‚
        movie_input = keras.layers.Input(shape=(), name='movie_id')
        movie_embedding = keras.layers.Embedding(num_movies, self.embedding_size, name='movie_embedding')(movie_input)
        movie_vec = keras.layers.Flatten(name='movie_flatten')(movie_embedding)
        
        # ç‰¹å¾èåˆå’Œå¤šå±‚ç¥ç»ç½‘ç»œ
        concat = keras.layers.Concatenate(name='concat')([user_vec, movie_vec])
        dense = concat
        for units in self.hidden_units:
            dense = keras.layers.Dense(units, activation='relu')(dense)
            dense = keras.layers.Dropout(0.2)(dense)
        # è¾“å‡ºå±‚ - è¯„åˆ†é¢„æµ‹
        output = keras.layers.Dense(1, activation='linear', name='rating_output')(dense)
        
        # åˆ›å»ºå’Œç¼–è¯‘æ¨¡å‹
        model = keras.Model(inputs=[user_input, movie_input], outputs=output)
        model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse', metrics=['mae'])
        
        self.model = model
        return model
    
    def train(self, interactions_df, epochs=50, batch_size=256, validation_split=0.2):
        """è®­ç»ƒæ¨¡å‹"""
        print("å¼€å§‹è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹...")
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        X_users = interactions_df['user_encoded'].values
        X_movies = interactions_df['movie_encoded'].values
        y_ratings = interactions_df['rating'].values
        
        # åˆ†å‰²è®­ç»ƒå’ŒéªŒè¯æ•°æ®
        X_users_train, X_users_val, X_movies_train, X_movies_val, y_train, y_val = train_test_split(
            X_users, X_movies, y_ratings, test_size=validation_split, random_state=42
        )
        
        # è®­ç»ƒæ¨¡å‹
        history = self.model.fit(
            [X_users_train, X_movies_train], y_train,
            validation_data=([X_users_val, X_movies_val], y_val),
            epochs=epochs, batch_size=batch_size, verbose=1
        )
        
        print("æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        return history
    
    def predict_rating(self, user_id, movie_id):
        """é¢„æµ‹ç”¨æˆ·å¯¹ç”µå½±çš„è¯„åˆ†"""
        try:
            user_encoded = self.user_encoder.transform([user_id])[0]
            movie_encoded = self.movie_encoder.transform([movie_id])[0]
            rating = self.model.predict([np.array([user_encoded]), np.array([movie_encoded])])[0][0]
            return max(1, min(10, rating))
        except:
            return 5.0
    
    def recommend_movies(self, user_id, movies_df, top_n=10):
        """ä¸ºç”¨æˆ·æ¨èç”µå½±"""
        movie_ratings = []
        
        for idx, movie in movies_df.iterrows():
            predicted_rating = self.predict_rating(user_id, movie['id'])
            movie_ratings.append({
                'title': movie['title'],
                'movie_id': movie['id'],
                'predicted_rating': predicted_rating,
                'actual_rating': movie['vote_average'],
                'genres': movie.get('genres', 'N/A')
            })
        
        # æŒ‰é¢„æµ‹è¯„åˆ†æ’åºå¹¶è¿”å›top-n
        movie_ratings.sort(key=lambda x: x['predicted_rating'], reverse=True)
        return movie_ratings[:top_n]
    
    def get_movie_embeddings(self):
        """è·å–ç”µå½±çš„åµŒå…¥å‘é‡ï¼Œå¯ç”¨äºç›¸ä¼¼åº¦è®¡ç®—"""
        if self.model is None:
            return None
        movie_embedding_layer = self.model.get_layer('movie_embedding')
        return movie_embedding_layer.get_weights()[0]

# ======================== æ·±åº¦å­¦ä¹ æ¼”ç¤ºå‡½æ•° ========================

def demo_deep_learning_recommendation():
    """æ·±åº¦å­¦ä¹ æ¨èç³»ç»Ÿæ¼”ç¤º"""
    print("\n" + "="*60)
    print("           æ·±åº¦å­¦ä¹ ç”µå½±æ¨èç³»ç»Ÿæ¼”ç¤º")
    print("="*60)
    
    # åˆå§‹åŒ–å¹¶è®­ç»ƒæ¨¡å‹
    dl_recommender = DeepLearningRecommendationSystem()
    interactions_df = dl_recommender.prepare_data(movies_df.head(100))
    
    num_users = interactions_df['user_encoded'].nunique()
    num_movies = interactions_df['movie_encoded'].nunique()
    model = dl_recommender.build_model(num_users, num_movies)
    
    print("\næ¨¡å‹æ¶æ„:")
    model.summary()
    
    # è®­ç»ƒæ¨¡å‹
    history = dl_recommender.train(interactions_df, epochs=20, batch_size=128)
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    
    plt.subplot(1, 2, 2)
    plt.plot(history.history['mae'], label='Training MAE')
    plt.plot(history.history['val_mae'], label='Validation MAE')
    plt.title('Model MAE')
    plt.xlabel('Epoch')
    plt.ylabel('MAE')
    plt.legend()
    
    plt.tight_layout()
    plt.show()
    
    # ç”Ÿæˆæ¨èå¹¶å±•ç¤ºç»“æœ
    print("\næ·±åº¦å­¦ä¹ æ¨èç»“æœ:")
    sample_user = interactions_df['user_id'].iloc[0]
    recommendations = dl_recommender.recommend_movies(sample_user, movies_df.head(100), top_n=10)
    
    print(f"\nä¸ºç”¨æˆ· {sample_user} æ¨èçš„ç”µå½±:")
    for i, rec in enumerate(recommendations, 1):
        print(f"{i:2d}. {rec['title']:<30} é¢„æµ‹è¯„åˆ†: {rec['predicted_rating']:.2f} å®é™…è¯„åˆ†: {rec['actual_rating']:.1f}")
    
    return dl_recommender

# ======================== æ··åˆæ¨èç³»ç»Ÿ ========================

class HybridRecommendationSystem:
    """æ··åˆæ¨èç³»ç»Ÿ - ç»“åˆåŸºäºå†…å®¹å’Œæ·±åº¦å­¦ä¹ çš„æ¨è"""
    
    def __init__(self, dl_recommender, content_sim_matrix, weight_dl=0.6, weight_content=0.4):
        self.dl_recommender = dl_recommender
        self.content_sim_matrix = content_sim_matrix
        self.weight_dl = weight_dl
        self.weight_content = weight_content
    
    def hybrid_recommend(self, user_id, movie_title, movies_df, top_n=10):
        """æ··åˆæ¨èï¼šç»“åˆæ·±åº¦å­¦ä¹ å’ŒåŸºäºå†…å®¹çš„æ¨è"""
        # æ·±åº¦å­¦ä¹ æ¨è
        dl_recommendations = self.dl_recommender.recommend_movies(user_id, movies_df, top_n=20)
        dl_scores = {rec['title']: rec['predicted_rating'] for rec in dl_recommendations}
        
        # åŸºäºå†…å®¹çš„æ¨è
        content_recommendations = get_recommendations(movie_title, self.content_sim_matrix)
        
        # åˆå¹¶åˆ†æ•°
        hybrid_scores = {}
        
        # æ·»åŠ æ·±åº¦å­¦ä¹ åˆ†æ•° (å½’ä¸€åŒ–åˆ°0-1)
        for title, score in dl_scores.items():
            hybrid_scores[title] = self.weight_dl * (score / 10.0)
        
        # æ·»åŠ åŸºäºå†…å®¹çš„åˆ†æ•° (åŸºäºæ’å)
        for i, title in enumerate(content_recommendations):
            content_score = (20 - i) / 20.0
            if title in hybrid_scores:
                hybrid_scores[title] += self.weight_content * content_score
            else:
                hybrid_scores[title] = self.weight_content * content_score
        
        # æ’åºå¹¶è¿”å›top-n
        sorted_recommendations = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)
        return [{'title': title, 'hybrid_score': score} for title, score in sorted_recommendations[:top_n]]

# ======================== ä¸»ç¨‹åºæ‰§è¡Œ ========================

if __name__ == "__main__":
    """è¿è¡Œæ¨èç³»ç»Ÿæ¼”ç¤º"""
    try:
        # è¿è¡Œæ·±åº¦å­¦ä¹ æ¨èç³»ç»Ÿ
        dl_system = demo_deep_learning_recommendation()
        print("\nâœ… æ·±åº¦å­¦ä¹ æ¨èç³»ç»Ÿæ¼”ç¤ºå®Œæˆ!")
        
        # æ··åˆæ¨èç³»ç»Ÿæ¼”ç¤º
        hybrid_system = HybridRecommendationSystem(dl_system, cosine_sim2)
        sample_user = "user_0_0"
        hybrid_recs = hybrid_system.hybrid_recommend(
            sample_user, "The Dark Knight Rises", movies_df.head(100), top_n=10
        )
        
        print(f"\nğŸ¯ æ··åˆæ¨èç³»ç»Ÿä¸ºç”¨æˆ·æ¨èçš„ç”µå½±:")
        for i, rec in enumerate(hybrid_recs, 1):
            print(f"{i:2d}. {rec['title']:<30} æ··åˆåˆ†æ•°: {rec['hybrid_score']:.3f}")
            
    except ImportError:
        print("\nâš ï¸  éœ€è¦å®‰è£… TensorFlow æ‰èƒ½è¿è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹")
        print("è¯·è¿è¡Œ: pip install tensorflow")
    except Exception as e:
        print(f"\nâŒ è¿è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹æ—¶å‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥æ•°æ®å’Œç¯å¢ƒé…ç½®")






